{
    "contents" : "##' Perform gbm cross-validation\n##'\n##' This function has far too many arguments, but there isn't the\n##' abstraction in gbm to lose them.\ngbmCrossVal <- function(cv.folds, nTrain, n.cores,\n                        class.stratify.cv, data,\n                        x, y, offset, distribution, w, var.monotone,\n                        n.trees, interaction.depth, n.minobsinnode,\n                        shrinkage, bag.fraction, mFeatures,\n                        var.names, response.name, group) {\n  i.train <- 1:nTrain\n  cv.group <- getCVgroup(distribution, class.stratify.cv, y,\n                         i.train, cv.folds, group)\n  ## build the models\n  cv.models <- gbmCrossValModelBuild(cv.folds, cv.group, n.cores,\n                                     i.train, x, y, offset,\n                                     distribution, w, var.monotone,\n                                     n.trees, interaction.depth,\n                                     n.minobsinnode, shrinkage,\n                                     bag.fraction, mFeatures, var.names,\n                                     response.name, group)\n  ## get the errors\n  cv.error  <- gbmCrossValErr(cv.models, cv.folds, cv.group, nTrain, n.trees)\n  best.iter.cv <- which.min(cv.error)\n\n  ## get the predictions\n  predictions <- gbmCrossValPredictions(cv.models, cv.folds, cv.group,\n                                        best.iter.cv, distribution,\n                                        data[i.train,,drop=FALSE], y)\n  list(error=cv.error,\n       predictions=predictions)\n}\n\n##' Get the gbm cross-validation error\ngbmCrossValErr <- function(cv.models, cv.folds, cv.group, nTrain, n.trees) {\n  in.group <- tabulate(cv.group, nbins=cv.folds)\n  cv.error <- vapply(1:cv.folds,\n                     function(index) {\n                       model <- cv.models[[index]]\n                       model$valid.error * in.group[[index]]\n                     }, double(n.trees))\n  ## this is now a (n.trees, cv.folds) matrix\n\n  ## and now a n.trees vector\n  rowSums(cv.error) / nTrain\n}\n\n##' Get the predictions for GBM cross validation\n##'\n##' This function is not as nice as it could be (leakage of y)\ngbmCrossValPredictions <- function(cv.models, cv.folds, cv.group,\n                                   best.iter.cv, distribution, data, y) {\n  ## test cv.group and data match\n  if (nrow(data) != length(cv.group)) {\n    stop(\"mismatch between data and cv.group\")\n  }\n  ## this is a little complicated due to multinomial distribution\n  num.cols <- if (distribution$name == \"multinomial\") {\n    nlevels(factor(y))\n  } else {\n    1\n  }\n  result <- matrix(nrow=nrow(data), ncol=num.cols)\n  ## there's no real reason to do this as other than a for loop\n  data.names <- names(data)\n  for (ind in 1:cv.folds) {\n    ## these are the particular elements\n    flag <- cv.group == ind\n    model <- cv.models[[ind]]\n    ## the %in% here is to handle coxph\n    my.data  <- data[flag, model$var.names, drop=FALSE]\n    predictions <- predict(model, newdata=my.data, n.trees=best.iter.cv)\n    predictions <- matrix(predictions, ncol=num.cols)\n    result[flag,] <- predictions\n  }\n\n  if (distribution$name != \"multinomial\") {\n    result <- as.numeric(result)\n  }\n\n  result\n}\n\n\n##' Perform gbm cross-validation\n##'\n##' This function has far too many arguments.\ngbmCrossValModelBuild <- function(cv.folds, cv.group, n.cores, i.train,\n                                  x, y, offset, distribution,\n                                  w, var.monotone, n.trees,\n                                  interaction.depth, n.minobsinnode,\n                                  shrinkage, bag.fraction, mFeatures,\n                                  var.names, response.name,\n                                  group) {\n  ## set up the cluster and add a finalizer\n  cluster <- gbmCluster(n.cores)\n  on.exit(if (!is.null(cluster)){ stopCluster(cluster) })\n\n  ## get ourselves some random seeds\n  seeds <- as.integer(runif(cv.folds, -(2^31 - 1), 2^31))\n\n  ## now do the cross-validation model builds\n  if ( ! is.null(cluster) ){\n    parallel::parLapply(cl=cluster, X=1:cv.folds,\n            gbmDoFold, i.train, x, y, offset, distribution,\n            w, var.monotone, n.trees,\n            interaction.depth, n.minobsinnode, shrinkage,\n            bag.fraction, mFeatures,\n            cv.group, var.names, response.name, group, seeds)\n  }\n  else {\n    lapply(X=1:cv.folds,\n            gbmDoFold, i.train, x, y, offset, distribution,\n            w, var.monotone, n.trees,\n            interaction.depth, n.minobsinnode, shrinkage,\n            bag.fraction, mFeatures,\n            cv.group, var.names, response.name, group, seeds) \n  }\n}\n",
    "created" : 1395540600638.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3009691532",
    "id" : "660733D0",
    "lastKnownWriteTime" : 1395627898,
    "path" : "C:/Users/Neil.Schneider/Repos/gbm/R/gbmCrossVal.R",
    "project_path" : "R/gbmCrossVal.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}