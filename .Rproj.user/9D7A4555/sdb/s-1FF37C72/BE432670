{
    "contents" : "# LEAST SQUARES EXAMPLE\n\ncat(\"Running least squares regression example.\\n\")\n# create some data\n\nN <- 1000\nX1 <- runif(N)\nX2 <- 2*runif(N)\nX3 <- factor(sample(letters[1:4],N,replace=T))\nX4 <- ordered(sample(letters[1:6],N,replace=T))\nX5 <- factor(sample(letters[1:3],N,replace=T))\nX6 <- 3*runif(N)\nmu <- c(-1,0,1,2)[as.numeric(X3)]\n\nSNR <- 10 # signal-to-noise ratio\nY <- X1**1.5 + 2 * (X2**.5) + mu\nsigma <- sqrt(var(Y)/SNR)\nY <- Y + rnorm(N,0,sigma)\n\n# create a bunch of missing values\nX1[sample(1:N,size=100)] <- NA\nX3[sample(1:N,size=300)] <- NA\n\n# random weights if you want to experiment with them\n# w <- rexp(N)\n# w <- N*w/sum(w)\nw <- rep(1,N)\n\ndata <- data.frame(Y=Y,X1=X1,X2=X2,X3=X3,X4=X4,X5=X5,X6=X6)\n\n# fit initial model\ngbm1 <- gbm(Y~X1+X2+X3+X4+X5+X6,         # formula\n            data=data,                   # dataset\n            var.monotone=c(0,0,0,0,0,0), # -1: monotone decrease, +1: monotone increase, 0: no monotone restrictions\n            distribution=\"gaussian\",     # bernoulli, adaboost, gaussian, poisson, coxph, or\n                                         # list(name=\"quantile\",alpha=0.05) for quantile regression\n            n.trees=2000,                 # number of trees\n            shrinkage=0.005,             # shrinkage or learning rate, 0.001 to 0.1 usually work\n            interaction.depth=3,         # 1: additive model, 2: two-way interactions, etc\n            bag.fraction = 0.5,          # subsampling fraction, 0.5 is probably best\n            train.fraction = 0.5,        # fraction of data for training, first train.fraction*N used for training\n            mFeatures = 3,\n            n.minobsinnode = 10,         # minimum number of obs needed in each node\n            keep.data=TRUE,\n            cv.folds=20,                 # do 10-fold cross-validation\n            verbose = FALSE,\n            n.cores=1)             # don't print progress\nstr(gbm1,max.level=1)\n# plot the performance\nbest.iter <- gbm.perf(gbm1,method=\"OOB\")  # returns out-of-bag estimated best number of trees\nbest.iter <- gbm.perf(gbm1,method=\"test\") # returns test set estimate of best number of trees\nbest.iter <- gbm.perf(gbm1,method=\"cv\")   # returns cv estimate of best number of trees\nplot(gbm1$cv.error)\n# plot variable influence\nsummary(gbm1,n.trees=1)         # based on the first tree\nsummary(gbm1,n.trees=best.iter) # based on the estimated best number of trees\n\n# print the first and last trees\nprint(pretty.gbm.tree(gbm1,1))\nprint(pretty.gbm.tree(gbm1,gbm1$n.trees))\n\nprint(gbm1$c.splits[1:3])\n\n# make some new data\nN <- 1000\nX1 <- runif(N)\nX2 <- 2*runif(N)\nX3 <- factor(sample(letters[1:4],N,replace=TRUE))\nX4 <- ordered(sample(letters[1:6],N,replace=TRUE))\nX5 <- factor(sample(letters[1:3],N,replace=TRUE))\nX6 <- 3*runif(N)\nmu <- c(-1,0,1,2)[as.numeric(X3)]\n\nY <- X1**1.5 + 2 * (X2**.5) + mu\nY <- Y + rnorm(N,0,sigma)\n\ndata2 <- data.frame(Y=Y,X1=X1,X2=X2,X3=X3,X4=X4,X5=X5,X6=X6)\nprint(data2[1:10,])\n\n# predict on the new data using \"best\" number of trees\nf.predict <- predict(gbm1,data2,best.iter) # f.predict will be on the canonical scale (logit,log,etc.)\n\nprint(f.predict[1:10])\n# least squares error\nprint(sum((data2$Y-f.predict)^2))\n\n# create marginal plots\n# plot variable X1,X2,X3 after \"best\" iterations\npar(mfrow=c(1,3))\nplot(gbm1,1,best.iter)\nplot(gbm1,2,best.iter)\nplot(gbm1,3,best.iter)\npar(mfrow=c(1,1))\nplot(gbm1,1:2,best.iter) # contour plot of variables 1 and 2 after \"best\" number iterations\nplot(gbm1,2:3,best.iter) # lattice plot of variables 2 and 3 after \"best\" number iterations\nplot(gbm1,3:4,best.iter) # lattice plot of variables 2 and 3 after \"best\" number iterations\n\nplot(gbm1,c(1,2,6),best.iter,cont=20) # 3-way plots\nplot(gbm1,1:3,best.iter)\nplot(gbm1,2:4,best.iter)\nplot(gbm1,3:5,best.iter)\n\n# check interactions\ninteract.gbm(gbm1,data=data,i.var=1:2,n.trees=best.iter)\n# get all two way interactions\ni.var <- subset(expand.grid(x1=1:6,x2=1:6), x1<x2)\nrownames(i.var) <- apply(i.var,1,paste,collapse=\":\",sep=\"\")\napply(i.var,1,\n      function(i.var) interact.gbm(gbm1,data=data,i.var=i.var,n.trees=best.iter))\n\n",
    "created" : 1395538774789.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2684721212",
    "id" : "BE432670",
    "lastKnownWriteTime" : 1395633880,
    "path" : "C:/Users/Neil.Schneider/Repos/gbm/demo/gaussian.R",
    "project_path" : "demo/gaussian.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}